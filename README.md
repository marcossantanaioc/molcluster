molcluster
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## How to use

pip install molcluster

You can use any function to generate descriptors for the molecules in
the dataset. For instance, we could use [Morgan
fingerprints](https://pubs.acs.org/doi/10.1021/ci100050t) from
[RDkit](https://www.rdkit.org/docs/GettingStartedInPython.html) to
generate a vector of 1024 bits for each molecule.

``` python
from molcluster.unsupervised_learning.clustering import KMeansClustering, HDBSCANClustering, ButinaClustering, HierarchicalClustering
from molcluster.unsupervised_learning.transform import UMAPTransform, PCATransform
```

    2022-08-28 11:46:45.842314: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
    2022-08-28 11:46:45.842380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

``` python
data = pd.read_csv('../data/fxa_processed.csv')
```

``` python
X = np.array([Chem.AllChem.GetMorganFingerprintAsBitVect(x, radius=1024) for x in list(map(Chem.MolFromSmiles, data.processed_smiles.values))])
```

# Dimensionality reduction

## Principal component analysis (PCA)

``` python
pca_reducer = PCATransform(X)
```

``` python
pca_embeddings = pca_reducer.reduce(n_components=2)
pca_embeddings[0:5]
```

    array([[1.21502428, 0.45049712],
           [1.44545485, 0.62502843],
           [1.51305965, 0.85847056],
           [3.77443421, 1.29465267],
           [3.65428094, 1.80748745]])

## UMAP

``` python
umap_reducer = UMAPTransform(X)
```

``` python
umap_embeddings = umap_reducer.reduce(n_neighbors=10, min_dist=0.25, metric='euclidean')
umap_embeddings[0:5]
```

    OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.

    array([[ 3.7038584,  5.6686788],
           [ 3.642379 ,  5.562135 ],
           [ 3.5490208,  5.5986824],
           [16.006702 ,  3.189072 ],
           [15.276152 ,  1.054887 ]], dtype=float32)

# Clustering

## Kmeans clustering with 10 clusters

``` python
clustering_kmeans = KMeansClustering(X)
labels = clustering_kmeans.cluster(n_clusters=10)
labels[0:5]
```

    array([3, 3, 3, 6, 6], dtype=int32)

### Using the elbow method to select the optimal number of clusters

``` python
clustering_kmeans.elbow_method(n_clusters=np.arange(2, 20))
```

![](index_files/figure-gfm/cell-10-output-1.png)

## Butina clustering with similarity threshold \> 0.7

``` python
mol_list = data.processed_smiles.values
```

``` python
clustering_butina = ButinaClustering(mol_list)
labels = clustering_butina.cluster(sim_cutoff=0.7)
labels[0:5]
```

    Calculating Fingerprints:   0%|          | 0/3503 [00:00<?, ?it/s]

    [34, 34, 34, 1, 131]

## HDBSCAN clustering

``` python
clustering_hdbscan = HDBSCANClustering(X)
labels = clustering_hdbscan.cluster(min_cluster_size=5,min_samples=1,metric='euclidean')
```

``` python
np.unique(labels)[0:5]
```

    array([-1,  0,  1,  2,  3])

## Agglomerative clustering (e.g. using Ward’s method)

``` python
clustering_agg = HierarchicalClustering(X)
```

``` python
labels = clustering_agg.cluster(n_clusters=None, distance_threshold=0.25, linkage='ward')
labels[0:5]
```

    array([2610, 3227, 2717, 3073, 2684])

### Plotting a dendrogram

``` python
clustering_agg.plot_dendrogram(truncate_mode="level", p=5)
```

![](index_files/figure-gfm/cell-17-output-1.png)
