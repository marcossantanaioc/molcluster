{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp unsupervised_learning.clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfa24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f5f32-c5d1-4f67-80ef-85db6dd51110",
   "metadata": {},
   "source": [
    "# clustering\n",
    "\n",
    "> Contains classes to perform clustering, including agglomerative clustering, k-means, hdbscan and Butina clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278faa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import optuna\n",
    "\n",
    "from fastcore.basics import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.meta import *\n",
    "from molcluster.typing_basics import *\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import hdbscan\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.AtomPairs import Pairs\n",
    "\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseClustering:\n",
    "    \n",
    "    \"\"\"Base class to perform clustering on a collection of molecules. \n",
    "    Use children classes `KMeansClustering`, `HDBSCANClustering`, `ButinaClustering` to cluster molecules\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def cluster(self):\n",
    "        pass\n",
    "                \n",
    "    @property\n",
    "    def clusterer(self):\n",
    "        return self._clusterer\n",
    "    \n",
    "    @clusterer.setter\n",
    "    def clusterer(self, i):\n",
    "        self._clusterer = i\n",
    "        \n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    \n",
    "    @labels.setter\n",
    "    def labels(self, i):\n",
    "        if isinstance(i, Sequence) and not isinstance(i, str):\n",
    "            self._labels = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686520ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L35){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseClustering\n",
       "\n",
       ">      BaseClustering ()\n",
       "\n",
       "Base class to perform clustering on a collection of molecules. \n",
       "Use children classes `KMeansClustering`, `HDBSCANClustering`, `ButinaClustering` to cluster molecules"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L35){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseClustering\n",
       "\n",
       ">      BaseClustering ()\n",
       "\n",
       "Base class to perform clustering on a collection of molecules. \n",
       "Use children classes `KMeansClustering`, `HDBSCANClustering`, `ButinaClustering` to cluster molecules"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaseClustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e19ae-e8b5-43c6-bc01-8a6e70b33307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "class HierarchicalClustering(BaseClustering):\n",
    "    \n",
    "    \"\"\"Performs agglomerative hierarchical clustering on a dataset of molecules\n",
    "    \n",
    "    Attributes:\n",
    "\n",
    "    dataset : numpy.array\n",
    "        An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
    "        \n",
    "        \n",
    "    Methods:\n",
    "\n",
    "    cluster(n_clusters:int)\n",
    "        Performs k-means clustering on ´self.dataset´\n",
    "        \n",
    "             \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset : ArrayLike):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "            dataset : numpy.array\n",
    "        \n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "            \n",
    "    def cluster(self,n_clusters:int=2,\n",
    "                affinity:str='euclidean', \n",
    "                memory=None, \n",
    "                connectivity=None,\n",
    "                compute_full_tree='auto',\n",
    "                linkage='ward',\n",
    "                distance_threshold=None,\n",
    "                compute_distances=False):\n",
    "        \n",
    "        \"\"\"Clustering molecules using different hierarchical methods available on scikit-learn.\n",
    "        \n",
    "    Arguments:\n",
    "\n",
    "        n_clusters : int or None, default=2\n",
    "            The number of clusters to find. It must be ``None`` if\n",
    "            ``distance_threshold`` is not ``None``.\n",
    "\n",
    "        affinity : str or callable, default='euclidean'\n",
    "            Metric used to compute the linkage. Can be \"euclidean\", \"l1\", \"l2\",\n",
    "            \"manhattan\", \"cosine\", or \"precomputed\".\n",
    "            If linkage is \"ward\", only \"euclidean\" is accepted.\n",
    "            If \"precomputed\", a distance matrix (instead of a similarity matrix)\n",
    "            is needed as input for the fit method.\n",
    "\n",
    "        memory : str or object with the joblib.Memory interface, default=None\n",
    "            Used to cache the output of the computation of the tree.\n",
    "            By default, no caching is done. If a string is given, it is the\n",
    "            path to the caching directory.\n",
    "\n",
    "        connectivity : array-like or callable, default=None\n",
    "            Connectivity matrix. Defines for each sample the neighboring\n",
    "            samples following a given structure of the data.\n",
    "            This can be a connectivity matrix itself or a callable that transforms\n",
    "            the data into a connectivity matrix, such as derived from\n",
    "            `kneighbors_graph`. Default is ``None``, i.e, the\n",
    "            hierarchical clustering algorithm is unstructured.\n",
    "\n",
    "        compute_full_tree : 'auto' or bool, default='auto'\n",
    "            Stop early the construction of the tree at ``n_clusters``. This is\n",
    "            useful to decrease computation time if the number of clusters is not\n",
    "            small compared to the number of samples. This option is useful only\n",
    "            when specifying a connectivity matrix. Note also that when varying the\n",
    "            number of clusters and using caching, it may be advantageous to compute\n",
    "            the full tree. It must be ``True`` if ``distance_threshold`` is not\n",
    "            ``None``. By default `compute_full_tree` is \"auto\", which is equivalent\n",
    "            to `True` when `distance_threshold` is not `None` or that `n_clusters`\n",
    "            is inferior to the maximum between 100 or `0.02 * n_samples`.\n",
    "            Otherwise, \"auto\" is equivalent to `False`.\n",
    "\n",
    "        linkage : {'ward', 'complete', 'average', 'single'}, default='ward'\n",
    "            Which linkage criterion to use. The linkage criterion determines which\n",
    "            distance to use between sets of observation. The algorithm will merge\n",
    "            the pairs of cluster that minimize this criterion.\n",
    "            - 'ward' minimizes the variance of the clusters being merged.\n",
    "            - 'average' uses the average of the distances of each observation of\n",
    "              the two sets.\n",
    "            - 'complete' or 'maximum' linkage uses the maximum distances between\n",
    "              all observations of the two sets.\n",
    "            - 'single' uses the minimum of the distances between all observations\n",
    "              of the two sets.\n",
    "\n",
    "        distance_threshold : float, default=None\n",
    "            The linkage distance threshold above which, clusters will not be\n",
    "            merged. If not ``None``, ``n_clusters`` must be ``None`` and\n",
    "            ``compute_full_tree`` must be ``True``.\n",
    "\n",
    "        compute_distances : bool, default=False\n",
    "            Computes distances between clusters even if `distance_threshold` is not\n",
    "            used. This can be used to make dendrogram visualization, but introduces\n",
    "            a computational and memory overhead.\n",
    "            \n",
    "            \n",
    "        Returns:\n",
    "    \n",
    "            labels : np.array\n",
    "                Clustering labels\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        cls = AgglomerativeClustering(n_clusters=n_clusters,\n",
    "                affinity=affinity, \n",
    "                memory=memory, \n",
    "                connectivity=connectivity,\n",
    "                compute_full_tree=compute_full_tree,\n",
    "                linkage=linkage,\n",
    "                distance_threshold=distance_threshold,\n",
    "                compute_distances=compute_distances)\n",
    "\n",
    "        cls.fit(self.dataset)\n",
    "        \n",
    "        self._clusterer = cls\n",
    "        self._labels = cls.labels_\n",
    "        return self._labels\n",
    "    \n",
    "    def plot_dendrogram(self, figsize:tuple=(12,9), **kwargs):\n",
    "        \n",
    "        \"\"\"Plots the dendrogram generated from the hierarchical clustering.\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "        figsize : tuple (default=(12,9))\n",
    "            Figure size for the plot.\n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        from scipy.cluster.hierarchy import dendrogram\n",
    "       \n",
    "        model = self.clusterer\n",
    "\n",
    "        # Plot Elbow\n",
    "        sns.set_context('paper',font_scale=2.5)\n",
    "        sns.set_style('whitegrid')\n",
    "\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "        # create the counts of samples under each node\n",
    "        counts = np.zeros(model.children_.shape[0])\n",
    "        n_samples = len(model.labels_)\n",
    "        for i, merge in enumerate(model.children_):\n",
    "            current_count = 0\n",
    "            for child_idx in merge:\n",
    "                if child_idx < n_samples:\n",
    "                    current_count += 1  # leaf node\n",
    "                else:\n",
    "                    current_count += counts[child_idx - n_samples]\n",
    "            counts[i] = current_count\n",
    "\n",
    "        linkage_matrix = np.column_stack(\n",
    "            [model.children_, model.distances_, counts]\n",
    "        ).astype(float)\n",
    "\n",
    "        # Plot the corresponding dendrogram\n",
    "        dendrogram(linkage_matrix, ax=ax,**kwargs)\n",
    "\n",
    "        ax.set_xlabel('Number of compounds in node (or index of point if no parenthesis).',fontsize=14)\n",
    "\n",
    "\n",
    "        ax.set_ylabel(f'{model.affinity.capitalize()} distance',fontsize=14)\n",
    "        sns.despine(right=True,top=True)\n",
    "        plt.title('Dendrogram',fontweight='bold',fontsize=20)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticklabels(ax.get_xticks(), size = 12)\n",
    "        for i in ax.spines.items():\n",
    "            i[1].set_linewidth(1.5)\n",
    "            i[1].set_color('k')\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd485f-6a02-4a56-a7bc-23b04327452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HierarchicalClustering.cluster\n",
       "\n",
       ">      HierarchicalClustering.cluster (n_clusters:int=2,\n",
       ">                                      affinity:str='euclidean', memory=None,\n",
       ">                                      connectivity=None,\n",
       ">                                      compute_full_tree='auto', linkage='ward',\n",
       ">                                      distance_threshold=None,\n",
       ">                                      compute_distances=False)\n",
       "\n",
       "Clustering molecules using different hierarchical methods available on scikit-learn.\n",
       "    \n",
       "Arguments:\n",
       "\n",
       "    n_clusters : int or None, default=2\n",
       "        The number of clusters to find. It must be ``None`` if\n",
       "        ``distance_threshold`` is not ``None``.\n",
       "\n",
       "    affinity : str or callable, default='euclidean'\n",
       "        Metric used to compute the linkage. Can be \"euclidean\", \"l1\", \"l2\",\n",
       "        \"manhattan\", \"cosine\", or \"precomputed\".\n",
       "        If linkage is \"ward\", only \"euclidean\" is accepted.\n",
       "        If \"precomputed\", a distance matrix (instead of a similarity matrix)\n",
       "        is needed as input for the fit method.\n",
       "\n",
       "    memory : str or object with the joblib.Memory interface, default=None\n",
       "        Used to cache the output of the computation of the tree.\n",
       "        By default, no caching is done. If a string is given, it is the\n",
       "        path to the caching directory.\n",
       "\n",
       "    connectivity : array-like or callable, default=None\n",
       "        Connectivity matrix. Defines for each sample the neighboring\n",
       "        samples following a given structure of the data.\n",
       "        This can be a connectivity matrix itself or a callable that transforms\n",
       "        the data into a connectivity matrix, such as derived from\n",
       "        `kneighbors_graph`. Default is ``None``, i.e, the\n",
       "        hierarchical clustering algorithm is unstructured.\n",
       "\n",
       "    compute_full_tree : 'auto' or bool, default='auto'\n",
       "        Stop early the construction of the tree at ``n_clusters``. This is\n",
       "        useful to decrease computation time if the number of clusters is not\n",
       "        small compared to the number of samples. This option is useful only\n",
       "        when specifying a connectivity matrix. Note also that when varying the\n",
       "        number of clusters and using caching, it may be advantageous to compute\n",
       "        the full tree. It must be ``True`` if ``distance_threshold`` is not\n",
       "        ``None``. By default `compute_full_tree` is \"auto\", which is equivalent\n",
       "        to `True` when `distance_threshold` is not `None` or that `n_clusters`\n",
       "        is inferior to the maximum between 100 or `0.02 * n_samples`.\n",
       "        Otherwise, \"auto\" is equivalent to `False`.\n",
       "\n",
       "    linkage : {'ward', 'complete', 'average', 'single'}, default='ward'\n",
       "        Which linkage criterion to use. The linkage criterion determines which\n",
       "        distance to use between sets of observation. The algorithm will merge\n",
       "        the pairs of cluster that minimize this criterion.\n",
       "        - 'ward' minimizes the variance of the clusters being merged.\n",
       "        - 'average' uses the average of the distances of each observation of\n",
       "          the two sets.\n",
       "        - 'complete' or 'maximum' linkage uses the maximum distances between\n",
       "          all observations of the two sets.\n",
       "        - 'single' uses the minimum of the distances between all observations\n",
       "          of the two sets.\n",
       "\n",
       "    distance_threshold : float, default=None\n",
       "        The linkage distance threshold above which, clusters will not be\n",
       "        merged. If not ``None``, ``n_clusters`` must be ``None`` and\n",
       "        ``compute_full_tree`` must be ``True``.\n",
       "\n",
       "    compute_distances : bool, default=False\n",
       "        Computes distances between clusters even if `distance_threshold` is not\n",
       "        used. This can be used to make dendrogram visualization, but introduces\n",
       "        a computational and memory overhead.\n",
       "        \n",
       "        \n",
       "    Returns:\n",
       "\n",
       "        labels : np.array\n",
       "            Clustering labels\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HierarchicalClustering.cluster\n",
       "\n",
       ">      HierarchicalClustering.cluster (n_clusters:int=2,\n",
       ">                                      affinity:str='euclidean', memory=None,\n",
       ">                                      connectivity=None,\n",
       ">                                      compute_full_tree='auto', linkage='ward',\n",
       ">                                      distance_threshold=None,\n",
       ">                                      compute_distances=False)\n",
       "\n",
       "Clustering molecules using different hierarchical methods available on scikit-learn.\n",
       "    \n",
       "Arguments:\n",
       "\n",
       "    n_clusters : int or None, default=2\n",
       "        The number of clusters to find. It must be ``None`` if\n",
       "        ``distance_threshold`` is not ``None``.\n",
       "\n",
       "    affinity : str or callable, default='euclidean'\n",
       "        Metric used to compute the linkage. Can be \"euclidean\", \"l1\", \"l2\",\n",
       "        \"manhattan\", \"cosine\", or \"precomputed\".\n",
       "        If linkage is \"ward\", only \"euclidean\" is accepted.\n",
       "        If \"precomputed\", a distance matrix (instead of a similarity matrix)\n",
       "        is needed as input for the fit method.\n",
       "\n",
       "    memory : str or object with the joblib.Memory interface, default=None\n",
       "        Used to cache the output of the computation of the tree.\n",
       "        By default, no caching is done. If a string is given, it is the\n",
       "        path to the caching directory.\n",
       "\n",
       "    connectivity : array-like or callable, default=None\n",
       "        Connectivity matrix. Defines for each sample the neighboring\n",
       "        samples following a given structure of the data.\n",
       "        This can be a connectivity matrix itself or a callable that transforms\n",
       "        the data into a connectivity matrix, such as derived from\n",
       "        `kneighbors_graph`. Default is ``None``, i.e, the\n",
       "        hierarchical clustering algorithm is unstructured.\n",
       "\n",
       "    compute_full_tree : 'auto' or bool, default='auto'\n",
       "        Stop early the construction of the tree at ``n_clusters``. This is\n",
       "        useful to decrease computation time if the number of clusters is not\n",
       "        small compared to the number of samples. This option is useful only\n",
       "        when specifying a connectivity matrix. Note also that when varying the\n",
       "        number of clusters and using caching, it may be advantageous to compute\n",
       "        the full tree. It must be ``True`` if ``distance_threshold`` is not\n",
       "        ``None``. By default `compute_full_tree` is \"auto\", which is equivalent\n",
       "        to `True` when `distance_threshold` is not `None` or that `n_clusters`\n",
       "        is inferior to the maximum between 100 or `0.02 * n_samples`.\n",
       "        Otherwise, \"auto\" is equivalent to `False`.\n",
       "\n",
       "    linkage : {'ward', 'complete', 'average', 'single'}, default='ward'\n",
       "        Which linkage criterion to use. The linkage criterion determines which\n",
       "        distance to use between sets of observation. The algorithm will merge\n",
       "        the pairs of cluster that minimize this criterion.\n",
       "        - 'ward' minimizes the variance of the clusters being merged.\n",
       "        - 'average' uses the average of the distances of each observation of\n",
       "          the two sets.\n",
       "        - 'complete' or 'maximum' linkage uses the maximum distances between\n",
       "          all observations of the two sets.\n",
       "        - 'single' uses the minimum of the distances between all observations\n",
       "          of the two sets.\n",
       "\n",
       "    distance_threshold : float, default=None\n",
       "        The linkage distance threshold above which, clusters will not be\n",
       "        merged. If not ``None``, ``n_clusters`` must be ``None`` and\n",
       "        ``compute_full_tree`` must be ``True``.\n",
       "\n",
       "    compute_distances : bool, default=False\n",
       "        Computes distances between clusters even if `distance_threshold` is not\n",
       "        used. This can be used to make dendrogram visualization, but introduces\n",
       "        a computational and memory overhead.\n",
       "        \n",
       "        \n",
       "    Returns:\n",
       "\n",
       "        labels : np.array\n",
       "            Clustering labels\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HierarchicalClustering.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846c88d-0283-4bee-b31b-b14301609c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HierarchicalClustering.plot_dendrogram\n",
       "\n",
       ">      HierarchicalClustering.plot_dendrogram (figsize:tuple=(12, 9), **kwargs)\n",
       "\n",
       "Plots the dendrogram generated from the hierarchical clustering.\n",
       "\n",
       "Arguments:\n",
       "    \n",
       "figsize : tuple (default=(12,9))\n",
       "    Figure size for the plot.\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HierarchicalClustering.plot_dendrogram\n",
       "\n",
       ">      HierarchicalClustering.plot_dendrogram (figsize:tuple=(12, 9), **kwargs)\n",
       "\n",
       "Plots the dendrogram generated from the hierarchical clustering.\n",
       "\n",
       "Arguments:\n",
       "    \n",
       "figsize : tuple (default=(12,9))\n",
       "    Figure size for the plot.\n",
       "    \n",
       "    "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HierarchicalClustering.plot_dendrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "class KMeansClustering(BaseClustering):\n",
    "    \n",
    "    \"\"\"Performs k-means clustering on a dataset of molecules\n",
    "    \n",
    "    Attributes:\n",
    "\n",
    "    dataset : numpy.array\n",
    "        An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
    "        \n",
    "        \n",
    "    Methods:\n",
    "\n",
    "    cluster(n_clusters:int)\n",
    "        Performs k-means clustering on ´self.dataset´\n",
    "        \n",
    "        \n",
    "    elbow_method(n_clusters:List, figsize:Tuple)\n",
    "        Uses the elbow method to find the optimal number of clusters\n",
    "             \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset : ArrayLike):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "\n",
    "            dataset : numpy.array\n",
    "        \n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "            \n",
    "    def cluster(self, n_clusters:int=10, **kwargs):\n",
    "        \n",
    "        \"\"\"Run k-means on the dataset\n",
    "        \n",
    "        Arguments:\n",
    "\n",
    "            n_clusters : int (default=10)\n",
    "                Number of clusters\n",
    "\n",
    "        Keyword arguments:\n",
    "            max_iter : int (default=5)\n",
    "            n_init : int (default=5)\n",
    "            init : str (default='k-means++')\n",
    "            random_state : int (default=None)\n",
    "            \n",
    "            \n",
    "        Returns:\n",
    "    \n",
    "            labels : np.array\n",
    "                Clustering labels\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        max_iter = kwargs.get('max_iter', 500)\n",
    "        n_init = kwargs.get('n_init', 10)\n",
    "        init = kwargs.get('init', 'k-means++')\n",
    "        random_state = kwargs.get('random_state', None)\n",
    "        \n",
    "        cls = KMeans(n_clusters=n_clusters, init=init, n_init=n_init, max_iter=max_iter, random_state=random_state)\n",
    "        cls.fit(self.dataset)\n",
    "        \n",
    "        self._clusterer = cls\n",
    "        self._labels = cls.labels_\n",
    "        return self._labels\n",
    "    \n",
    "    def elbow_method(self, n_clusters:List, figsize:Tuple=(12,9), **kwargs):\n",
    "\n",
    "        self.inertias = []\n",
    "        for n in n_clusters:\n",
    "            self.cluster(n, **kwargs)   \n",
    "            inertia = self.clusterer.inertia_\n",
    "            self.inertias.append(inertia)\n",
    "            \n",
    "        # Find elbow\n",
    "        params = {\"curve\": \"convex\",\n",
    "                    \"direction\": \"decreasing\"}\n",
    "        \n",
    "        knee_finder = KneeLocator(n_clusters, self.inertias, **params)\n",
    "        self.elbow_value = knee_finder.elbow\n",
    "        \n",
    "        # Plot Elbow\n",
    "        sns.set_context('paper',font_scale=2.0)\n",
    "        sns.set_style('whitegrid')\n",
    "        \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax=sns.lineplot(x=n_clusters, y=np.array(self.inertias), linewidth=2.5, marker='o', color='blue', markersize=7)\n",
    "\n",
    "        ax.set_xlabel('Number of clusters (K)')\n",
    "        ax.set_ylabel('Distortion')\n",
    "        sns.despine(right=True,top=True)\n",
    "        plt.title('K-means Elbow method',fontweight='bold',fontsize=22)\n",
    "        \n",
    "        if self.elbow_value is not None:\n",
    "            elbow_label = \"Elbow at $K={}$\".format(self.elbow_value)      \n",
    "            ax.axvline(self.elbow_value, c='k', linestyle=\"--\",label=elbow_label)\n",
    "            ax.legend(loc=\"best\", fontsize=18, frameon=True)\n",
    "        for i in ax.spines.items():\n",
    "            i[1].set_linewidth(1.5)\n",
    "            i[1].set_color('k')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf9512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L246){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### KMeansClustering\n",
       "\n",
       ">      KMeansClustering (dataset:Union[numpy._array_like._SupportsArray[numpy.dt\n",
       ">                        ype],numpy._nested_sequence._NestedSequence[numpy._arra\n",
       ">                        y_like._SupportsArray[numpy.dtype]],bool,int,float,comp\n",
       ">                        lex,str,bytes,numpy._nested_sequence._NestedSequence[Un\n",
       ">                        ion[bool,int,float,complex,str,bytes]]])\n",
       "\n",
       "Performs k-means clustering on a dataset of molecules\n",
       "\n",
       "Attributes:\n",
       "\n",
       "dataset : numpy.array\n",
       "    An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
       "    \n",
       "    \n",
       "Methods:\n",
       "\n",
       "cluster(n_clusters:int)\n",
       "    Performs k-means clustering on ´self.dataset´\n",
       "    \n",
       "    \n",
       "elbow_method(n_clusters:List, figsize:Tuple)\n",
       "    Uses the elbow method to find the optimal number of clusters\n",
       "         "
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L246){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### KMeansClustering\n",
       "\n",
       ">      KMeansClustering (dataset:Union[numpy._array_like._SupportsArray[numpy.dt\n",
       ">                        ype],numpy._nested_sequence._NestedSequence[numpy._arra\n",
       ">                        y_like._SupportsArray[numpy.dtype]],bool,int,float,comp\n",
       ">                        lex,str,bytes,numpy._nested_sequence._NestedSequence[Un\n",
       ">                        ion[bool,int,float,complex,str,bytes]]])\n",
       "\n",
       "Performs k-means clustering on a dataset of molecules\n",
       "\n",
       "Attributes:\n",
       "\n",
       "dataset : numpy.array\n",
       "    An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
       "    \n",
       "    \n",
       "Methods:\n",
       "\n",
       "cluster(n_clusters:int)\n",
       "    Performs k-means clustering on ´self.dataset´\n",
       "    \n",
       "    \n",
       "elbow_method(n_clusters:List, figsize:Tuple)\n",
       "    Uses the elbow method to find the optimal number of clusters\n",
       "         "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(KMeansClustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92856b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### KMeansClustering.cluster\n",
       "\n",
       ">      KMeansClustering.cluster (n_clusters:int=10, **kwargs)\n",
       "\n",
       "Run k-means on the dataset\n",
       "\n",
       "Arguments:\n",
       "\n",
       "    n_clusters : int (default=10)\n",
       "        Number of clusters\n",
       "\n",
       "Keyword arguments:\n",
       "    max_iter : int (default=5)\n",
       "    n_init : int (default=5)\n",
       "    init : str (default='k-means++')\n",
       "    random_state : int (default=None)\n",
       "    \n",
       "    \n",
       "Returns:\n",
       "\n",
       "    labels : np.array\n",
       "        Clustering labels"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### KMeansClustering.cluster\n",
       "\n",
       ">      KMeansClustering.cluster (n_clusters:int=10, **kwargs)\n",
       "\n",
       "Run k-means on the dataset\n",
       "\n",
       "Arguments:\n",
       "\n",
       "    n_clusters : int (default=10)\n",
       "        Number of clusters\n",
       "\n",
       "Keyword arguments:\n",
       "    max_iter : int (default=5)\n",
       "    n_init : int (default=5)\n",
       "    init : str (default='k-means++')\n",
       "    random_state : int (default=None)\n",
       "    \n",
       "    \n",
       "Returns:\n",
       "\n",
       "    labels : np.array\n",
       "        Clustering labels"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(KMeansClustering.cluster, name='KMeansClustering.cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export      \n",
    "class HDBSCANClustering(BaseClustering):\n",
    "    \n",
    "    \"\"\"Performs HDBSCAN clustering on a dataset of molecules\n",
    "    \n",
    "    \n",
    "    Attributes:\n",
    "\n",
    "        dataset : numpy.array\n",
    "            An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
    "\n",
    "\n",
    "    Methods:\n",
    "\n",
    "        cluster(n_clusters:int)\n",
    "            Performs k-means clustering on ´self.dataset´\n",
    "            \n",
    "        validate_clustering(X, labels)\n",
    "            Compute the density based cluster validity index for the clustering specified by labels and for each cluster in labels.\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset : ArrayLike):\n",
    "        self.dataset = dataset\n",
    "            \n",
    "            \n",
    "    def cluster(self, min_cluster_size:int=5, min_samples:int=None, metric:str='jaccard', **kwargs):\n",
    "        \n",
    "        \"\"\"Run HDBSCAN clustering on the dataset\n",
    "        \n",
    "        Arguments:\n",
    "\n",
    "\n",
    "           min_cluster_size : int, optional (default=5)\n",
    "               The minimum size of clusters; single linkage splits that contain\n",
    "               fewer points than this will be considered points \"falling out\" of a\n",
    "               cluster rather than a cluster splitting into two new clusters.\n",
    "\n",
    "           min_samples : int, optional (default=None)\n",
    "               The number of samples in a neighbourhood for a point to be\n",
    "               considered a core point.\n",
    "\n",
    "           metric : string, or callable, optional (default='euclidean')\n",
    "               The metric to use when calculating distance between instances in a\n",
    "               feature array. If metric is a string or callable, it must be one of\n",
    "               the options allowed by metrics.pairwise.pairwise_distances for its\n",
    "               metric parameter.\n",
    "               If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
    "               must be square.\n",
    "                              \n",
    "        Keyword arguments:\n",
    "        \n",
    "            See HDBSCAN documentation (https://hdbscan.readthedocs.io/en/latest/index.html)\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            labels : np.array\n",
    "                Clustering labels\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        cls = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric=metric, **kwargs)\n",
    "        cls.fit(self.dataset)\n",
    "        \n",
    "        self._clusterer = cls\n",
    "        self._labels = cls.labels_\n",
    "        return self._labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_clustering(X, labels, metric='euclidean', d=None, per_cluster_scores=False, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            X :array (n_samples, n_features) or (n_samples, n_samples)\n",
    "                The input data of the clustering. This can be the data, or, if metric is set to precomputed the pairwise distance matrix used for the clustering.\n",
    "            labels :array (n_samples)\n",
    "                The label array output by the clustering, providing an integral cluster label to each data point, with -1 for noise points.\n",
    "\n",
    "            metric :optional, string (default ‘euclidean’)\n",
    "                The metric used to compute distances for the clustering (and to be re-used in computing distances for mr distance). If set to precomputed then X is assumed to be the precomputed distance matrix between samples.\n",
    "            d :optional, integer (or None) (default None)\n",
    "                The number of features (dimension) of the dataset. This need only be set in the case of metric being set to precomputed, where the ambient dimension of the data is unknown to the function.\n",
    "\n",
    "            per_cluster_scores :optional, boolean (default False)\n",
    "                Whether to return the validity index for individual clusters. Defaults to False with the function returning a single float value for the whole clustering.\n",
    "\n",
    "        Returns:\n",
    "            validity_index : float\n",
    "                The density based cluster validity index for the clustering. This is a numeric value between -1 and 1, with higher values indicating a ‘better’ clustering.\n",
    "        \"\"\"\n",
    "        \n",
    "        return hdbscan.validity_index(X, labels, metric=metric, d=d, per_cluster_scores=per_cluster_scores, **kwargs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9083c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L351){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HDBSCANClustering\n",
       "\n",
       ">      HDBSCANClustering (dataset:Union[numpy._array_like._SupportsArray[numpy.d\n",
       ">                         type],numpy._nested_sequence._NestedSequence[numpy._ar\n",
       ">                         ray_like._SupportsArray[numpy.dtype]],bool,int,float,c\n",
       ">                         omplex,str,bytes,numpy._nested_sequence._NestedSequenc\n",
       ">                         e[Union[bool,int,float,complex,str,bytes]]])\n",
       "\n",
       "Performs HDBSCAN clustering on a dataset of molecules\n",
       "\n",
       "\n",
       "Attributes:\n",
       "\n",
       "    dataset : numpy.array\n",
       "        An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
       "\n",
       "\n",
       "Methods:\n",
       "\n",
       "    cluster(n_clusters:int)\n",
       "        Performs k-means clustering on ´self.dataset´\n",
       "        \n",
       "    validate_clustering(X, labels)\n",
       "        Compute the density based cluster validity index for the clustering specified by labels and for each cluster in labels."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L351){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HDBSCANClustering\n",
       "\n",
       ">      HDBSCANClustering (dataset:Union[numpy._array_like._SupportsArray[numpy.d\n",
       ">                         type],numpy._nested_sequence._NestedSequence[numpy._ar\n",
       ">                         ray_like._SupportsArray[numpy.dtype]],bool,int,float,c\n",
       ">                         omplex,str,bytes,numpy._nested_sequence._NestedSequenc\n",
       ">                         e[Union[bool,int,float,complex,str,bytes]]])\n",
       "\n",
       "Performs HDBSCAN clustering on a dataset of molecules\n",
       "\n",
       "\n",
       "Attributes:\n",
       "\n",
       "    dataset : numpy.array\n",
       "        An array of features with shape (n,p), where n is the number of molecules and p is the number of descriptors.\n",
       "\n",
       "\n",
       "Methods:\n",
       "\n",
       "    cluster(n_clusters:int)\n",
       "        Performs k-means clustering on ´self.dataset´\n",
       "        \n",
       "    validate_clustering(X, labels)\n",
       "        Compute the density based cluster validity index for the clustering specified by labels and for each cluster in labels."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HDBSCANClustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a4dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HDBSCANClustering.cluster\n",
       "\n",
       ">      HDBSCANClustering.cluster (min_cluster_size:int=5, min_samples:int=None,\n",
       ">                                 metric:str='jaccard', **kwargs)\n",
       "\n",
       "Run HDBSCAN clustering on the dataset\n",
       "\n",
       "Arguments:\n",
       "\n",
       "\n",
       "   min_cluster_size : int, optional (default=5)\n",
       "       The minimum size of clusters; single linkage splits that contain\n",
       "       fewer points than this will be considered points \"falling out\" of a\n",
       "       cluster rather than a cluster splitting into two new clusters.\n",
       "\n",
       "   min_samples : int, optional (default=None)\n",
       "       The number of samples in a neighbourhood for a point to be\n",
       "       considered a core point.\n",
       "\n",
       "   metric : string, or callable, optional (default='euclidean')\n",
       "       The metric to use when calculating distance between instances in a\n",
       "       feature array. If metric is a string or callable, it must be one of\n",
       "       the options allowed by metrics.pairwise.pairwise_distances for its\n",
       "       metric parameter.\n",
       "       If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
       "       must be square.\n",
       "                      \n",
       "Keyword arguments:\n",
       "\n",
       "    See HDBSCAN documentation (https://hdbscan.readthedocs.io/en/latest/index.html)\n",
       "    \n",
       "Returns:\n",
       "\n",
       "    labels : np.array\n",
       "        Clustering labels"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### HDBSCANClustering.cluster\n",
       "\n",
       ">      HDBSCANClustering.cluster (min_cluster_size:int=5, min_samples:int=None,\n",
       ">                                 metric:str='jaccard', **kwargs)\n",
       "\n",
       "Run HDBSCAN clustering on the dataset\n",
       "\n",
       "Arguments:\n",
       "\n",
       "\n",
       "   min_cluster_size : int, optional (default=5)\n",
       "       The minimum size of clusters; single linkage splits that contain\n",
       "       fewer points than this will be considered points \"falling out\" of a\n",
       "       cluster rather than a cluster splitting into two new clusters.\n",
       "\n",
       "   min_samples : int, optional (default=None)\n",
       "       The number of samples in a neighbourhood for a point to be\n",
       "       considered a core point.\n",
       "\n",
       "   metric : string, or callable, optional (default='euclidean')\n",
       "       The metric to use when calculating distance between instances in a\n",
       "       feature array. If metric is a string or callable, it must be one of\n",
       "       the options allowed by metrics.pairwise.pairwise_distances for its\n",
       "       metric parameter.\n",
       "       If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
       "       must be square.\n",
       "                      \n",
       "Keyword arguments:\n",
       "\n",
       "    See HDBSCAN documentation (https://hdbscan.readthedocs.io/en/latest/index.html)\n",
       "    \n",
       "Returns:\n",
       "\n",
       "    labels : np.array\n",
       "        Clustering labels"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(HDBSCANClustering.cluster, name='HDBSCANClustering.cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ce114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "class ButinaClustering(BaseClustering):\n",
    "    \n",
    "    \"\"\"Performs Butina clustering\n",
    "    \n",
    "    See original publication at: https://github.com/PatWalters/clusterama\n",
    "    \n",
    "    Attributes:\n",
    "\n",
    "        dataset : list\n",
    "            A list of SMILES.\n",
    "\n",
    "\n",
    "    Methods:\n",
    "\n",
    "        cluster(sim_cutoff:float, nbits:int, radius:int)\n",
    "            Performs Butina clustering on ´self.dataset´.\n",
    "            \n",
    "        get_fps(mol_list:list, nbits:int, radius:int)\n",
    "            Generate descriptors for ´self.dataset´.\n",
    "         \n",
    "        cluster_mols(mol_list, sim_cutoff:float, nbits:int, radius:int)\n",
    "            Cluster molecules.\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset:List, fp_type=\"rdkit\"):\n",
    "        self.dataset = dataset\n",
    "        self.fp_type = fp_type\n",
    "\n",
    "    def cluster(self,sim_cutoff:float, nbits:int=2048, radius:int=2):\n",
    "        \n",
    "        \"\"\"Run Butina clustering on the dataset\n",
    "        \n",
    "        Arguments:\n",
    "\n",
    "\n",
    "            sim_cutoff : float\n",
    "                The minimum Tanimoto similarity to consider for putting compounds in the same cluster\n",
    "                \n",
    "            nbits : int, optional (default=2048)\n",
    "                Number of bits of the fingerprints if ´fp_type´ is 'morgan2'\n",
    "                \n",
    "            radius : int, optional (default=2)\n",
    "                Radius of the fingerprints if ´fp_type´ is 'morgan2'\n",
    "                \n",
    "                \n",
    "            \n",
    "        Returns:\n",
    "\n",
    "            labels : np.array\n",
    "                Clustering labels\n",
    "        \n",
    "        \"\"\"        \n",
    "        \n",
    "        \n",
    "        mol_list = [Chem.MolFromSmiles(x) for x in tqdm(self.dataset,desc=\"Calculating Fingerprints\")]\n",
    "        return self.cluster_mols(mol_list, sim_cutoff, nbits, radius)\n",
    "\n",
    "    def get_fps(self, mol_list, nbits:int, radius:int):\n",
    "        \n",
    "        \n",
    "        fp_dict = {\n",
    "            \"morgan2\" : [AllChem.GetMorganFingerprintAsBitVect(x,radius,nbits) for x in mol_list],\n",
    "            \"rdkit\" : [Chem.RDKFingerprint(x) for x in mol_list],\n",
    "            \"maccs\" : [MACCSkeys.GenMACCSKeys(x) for x in mol_list],\n",
    "            \"ap\" : [Pairs.GetAtomPairFingerprint(x) for x in mol_list]\n",
    "            }\n",
    "        if fp_dict.get(self.fp_type) is None:\n",
    "            raise KeyError(f\"No fingerprint method defined for {self.fp_type}\")\n",
    "\n",
    "        return fp_dict[self.fp_type]\n",
    "    \n",
    "    def cluster_mols(self, mol_list, sim_cutoff:float, nbits:int, radius:int):\n",
    "        dist_cutoff = 1.0 - sim_cutoff\n",
    "        fp_list = self.get_fps(mol_list, nbits, radius)\n",
    "        dists = []\n",
    "        nfps = len(fp_list)\n",
    "        for i in range(1, nfps):\n",
    "            sims = DataStructs.BulkTanimotoSimilarity(fp_list[i],fp_list[:i])\n",
    "            dists.extend([1-x for x in sims])\n",
    "        mol_clusters = Butina.ClusterData(dists,nfps,dist_cutoff,isDistData=True)\n",
    "        cluster_id_list = [0]*nfps\n",
    "        for idx,cluster in enumerate(mol_clusters,1):\n",
    "            for member in cluster:\n",
    "                cluster_id_list[member] = idx\n",
    "        self._labels = [x-1 for x in cluster_id_list]\n",
    "        return self._labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9b305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L450){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ButinaClustering\n",
       "\n",
       ">      ButinaClustering (dataset:List, fp_type='rdkit')\n",
       "\n",
       "Performs Butina clustering\n",
       "\n",
       "See original publication at: https://github.com/PatWalters/clusterama\n",
       "\n",
       "Attributes:\n",
       "\n",
       "    dataset : list\n",
       "        A list of SMILES.\n",
       "\n",
       "\n",
       "Methods:\n",
       "\n",
       "    cluster(sim_cutoff:float, nbits:int, radius:int)\n",
       "        Performs Butina clustering on ´self.dataset´.\n",
       "        \n",
       "    get_fps(mol_list:list, nbits:int, radius:int)\n",
       "        Generate descriptors for ´self.dataset´.\n",
       "     \n",
       "    cluster_mols(mol_list, sim_cutoff:float, nbits:int, radius:int)\n",
       "        Cluster molecules.\n",
       "    "
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#L450){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ButinaClustering\n",
       "\n",
       ">      ButinaClustering (dataset:List, fp_type='rdkit')\n",
       "\n",
       "Performs Butina clustering\n",
       "\n",
       "See original publication at: https://github.com/PatWalters/clusterama\n",
       "\n",
       "Attributes:\n",
       "\n",
       "    dataset : list\n",
       "        A list of SMILES.\n",
       "\n",
       "\n",
       "Methods:\n",
       "\n",
       "    cluster(sim_cutoff:float, nbits:int, radius:int)\n",
       "        Performs Butina clustering on ´self.dataset´.\n",
       "        \n",
       "    get_fps(mol_list:list, nbits:int, radius:int)\n",
       "        Generate descriptors for ´self.dataset´.\n",
       "     \n",
       "    cluster_mols(mol_list, sim_cutoff:float, nbits:int, radius:int)\n",
       "        Cluster molecules.\n",
       "    "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ButinaClustering, name='ButinaClustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d8e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ButinaClustering.cluster\n",
       "\n",
       ">      ButinaClustering.cluster (sim_cutoff:float, nbits:int=2048, radius:int=2)\n",
       "\n",
       "Run Butina clustering on the dataset\n",
       "\n",
       "Arguments:\n",
       "\n",
       "\n",
       "    sim_cutoff : float\n",
       "        The minimum Tanimoto similarity to consider for putting compounds in the same cluster\n",
       "        \n",
       "    nbits : int, optional (default=2048)\n",
       "        Number of bits of the fingerprints if ´fp_type´ is 'morgan2'\n",
       "        \n",
       "    radius : int, optional (default=2)\n",
       "        Radius of the fingerprints if ´fp_type´ is 'morgan2'\n",
       "        \n",
       "        \n",
       "    \n",
       "Returns:\n",
       "\n",
       "    labels : np.array\n",
       "        Clustering labels"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/marcossantanaioc/molcluster/blob/master/molcluster/unsupervised_learning/clustering.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ButinaClustering.cluster\n",
       "\n",
       ">      ButinaClustering.cluster (sim_cutoff:float, nbits:int=2048, radius:int=2)\n",
       "\n",
       "Run Butina clustering on the dataset\n",
       "\n",
       "Arguments:\n",
       "\n",
       "\n",
       "    sim_cutoff : float\n",
       "        The minimum Tanimoto similarity to consider for putting compounds in the same cluster\n",
       "        \n",
       "    nbits : int, optional (default=2048)\n",
       "        Number of bits of the fingerprints if ´fp_type´ is 'morgan2'\n",
       "        \n",
       "    radius : int, optional (default=2)\n",
       "        Radius of the fingerprints if ´fp_type´ is 'morgan2'\n",
       "        \n",
       "        \n",
       "    \n",
       "Returns:\n",
       "\n",
       "    labels : np.array\n",
       "        Clustering labels"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ButinaClustering.cluster, name='ButinaClustering.cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06adb4-2100-4f6e-af69-b6129f2eea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285a955-6928-48ac-84c9-ee8110508201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3c244-170c-4152-8899-f68a6e867d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc4f9f-b76e-4099-abaa-b80b16d7c7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f2f16-9198-4db5-a5eb-03a941921991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad9292-c86b-4f18-8e8e-fe3b9d51e961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4f624-ec75-42f1-bb91-72ebe09af75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbba5e0-073a-4c9b-94e9-fbf19ee8f94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee80b70-4b77-487c-b2c5-5bed59306c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminformatics",
   "language": "python",
   "name": "cheminformatics"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
